{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":16887,"status":"ok","timestamp":1763787479174,"user":{"displayName":"ISHIKA KANYAL","userId":"01776562043666172481"},"user_tz":-330},"id":"EbVP0wup_HG6","outputId":"573f5226-3df9-4cff-b180-e8b591cd9ffd"},"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[?25l     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m0.0/7.8 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91mâ”â”â”â”â”â”â”\u001b[0m\u001b[90mâ•º\u001b[0m\u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.4/7.8 MB\u001b[0m \u001b[31m46.1 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[91mâ•¸\u001b[0m\u001b[90mâ”â”\u001b[0m \u001b[32m7.3/7.8 MB\u001b[0m \u001b[31m110.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m82.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n","  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n","  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","  Building wheel for grad-cam (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n"]}],"source":["!pip install gradio torch torchvision pillow numpy opencv-python grad-cam -q\n"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":15621,"status":"ok","timestamp":1763787501885,"user":{"displayName":"ISHIKA KANYAL","userId":"01776562043666172481"},"user_tz":-330},"id":"ynijR_fkWYS0","outputId":"e60c2751-254c-4893-a718-57102c671917"},"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[?25l     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m0.0/7.8 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91mâ”â”â”â”\u001b[0m\u001b[91mâ•¸\u001b[0m\u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m0.9/7.8 MB\u001b[0m \u001b[31m25.5 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[90mâ•º\u001b[0m\u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m4.5/7.8 MB\u001b[0m \u001b[31m60.1 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m79.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n","  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n","  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","  Building wheel for grad-cam (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n"]}],"source":["!pip install grad-cam==1.4.8 --no-cache-dir -q\n"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":21635,"status":"ok","timestamp":1763787525948,"user":{"displayName":"ISHIKA KANYAL","userId":"01776562043666172481"},"user_tz":-330},"id":"wbreYjumqY4n","outputId":"c23afc21-4d48-4cde-e502-c7800f24335b"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/gdrive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/gdrive')"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":997,"status":"ok","timestamp":1763787529706,"user":{"displayName":"ISHIKA KANYAL","userId":"01776562043666172481"},"user_tz":-330},"id":"zAX3YtuArNJi","outputId":"bd215198-2f30-4336-9654-f4817ff281b0"},"outputs":[{"output_type":"stream","name":"stdout","text":["app.py\t\tconfusion_matrix.png  garbage_dataset\ttraining_curves.png\n","best_model.pth\tfinalappmaking.ipynb  requirements.txt\twaste_training.ipynb\n"]}],"source":["!ls /content/gdrive/MyDrive/WasteClassification/"]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":496,"status":"ok","timestamp":1763787535986,"user":{"displayName":"ISHIKA KANYAL","userId":"01776562043666172481"},"user_tz":-330},"id":"OMWSn4aS_TY1","outputId":"1b8fe79c-ef86-40a3-9bd2-825e079cef40"},"outputs":[{"output_type":"stream","name":"stdout","text":["Overwriting /content/gdrive/MyDrive/WasteClassification/app.py\n"]}],"source":["%%writefile /content/gdrive/MyDrive/WasteClassification/app.py\n","import torch\n","import torch.nn as nn\n","import matplotlib as mpl\n","import matplotlib.pyplot as plt\n","import torchvision.transforms as transforms\n","import torchvision.models as models\n","from PIL import Image\n","import numpy as np\n","import cv2\n","from pytorch_grad_cam import GradCAM\n","from pytorch_grad_cam.utils.image import show_cam_on_image\n","import gradio as gr\n","import warnings\n","warnings.filterwarnings('ignore')\n","\n","DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n","print(f\"Using device: {DEVICE}\")\n","\n","MODEL_PATH = \"/content/gdrive/MyDrive/WasteClassification/best_model.pth\"\n","\n","net = models.efficientnet_b3(weights=None)\n","net.classifier[1] = nn.Linear(net.classifier[1].in_features, 12)\n","net.load_state_dict(torch.load(MODEL_PATH, map_location=DEVICE))\n","net.to(DEVICE)\n","net.eval()\n","\n","print(\"âœ“ Model loaded successfully!\")\n","\n","CLASSES = [\n","    'Battery', 'Biological', 'Brown-Glass', 'Cardboard',\n","    'Clothes', 'Green-Glass', 'Metal', 'Paper', 'Plastic',\n","    'Shoes', 'Trash', 'White-Glass'\n","]\n","\n","RECYCLABLE = {\n","    'Battery': False, 'Biological': False, 'Brown-Glass': True, 'Cardboard': True,\n","    'Clothes': True, 'Green-Glass': True, 'Metal': True, 'Paper': True,\n","    'Plastic': True, 'Shoes': False, 'Trash': False, 'White-Glass': True\n","}\n","\n","BIODEGRADABLE = {\n","    'Battery': False, 'Biological': True, 'Brown-Glass': False, 'Cardboard': True,\n","    'Clothes': False, 'Green-Glass': False, 'Metal': False, 'Paper': True,\n","    'Plastic': False, 'Shoes': False, 'Trash': False, 'White-Glass': False\n","}\n","\n","SUGGESTIONS = {\n","    \"Battery\": [\"Drop at e-waste center.\", \"Do not throw in general waste.\", \"Store safely.\"],\n","    \"Biological\": [\"Compost it.\", \"Put in organic waste bin.\", \"Use for soil enrichment.\"],\n","    \"Plastic\": [\"Clean & recycle.\", \"Reuse as containers.\", \"Avoid burning.\"],\n","    \"Paper\": [\"Recycle.\", \"Reuse for craft.\", \"Shred for packaging.\"],\n","    \"Metal\": [\"Recycle at scrap center.\", \"Store safely.\", \"Reuse if possible.\"],\n","    \"Trash\": [\"Put in general waste.\", \"Try reducing usage.\", \"Avoid mixing recyclable items.\"],\n","    \"Clothes\": [\"Donate to the needy.\", \"Recycle the fabric.\", \"Upcycle for cleaning.\"],\n","    \"Shoes\": [\"Donate wearable pairs.\", \"Recycle the sole material.\", \"Upcycle creatively.\"],\n","    \"Cardboard\": [\"Flatten & recycle.\", \"Reuse for packing.\", \"Use for compost if clean.\"],\n","    \"Green-Glass\": [\"Recycle.\", \"Reuse as containers.\", \"Handle carefully.\"],\n","    \"White-Glass\": [\"Recycle.\", \"Use creatively in house for decorative purposes.\", \"Avoid throwing it in trash.\"],\n","    \"Brown-Glass\": [\"Recycle.\", \"Reuse the bottle.\", \"Avoid breaking the glass.\"]\n","}\n","\n","TRANSFORM = transforms.Compose([\n","    transforms.Resize((224, 224)),\n","    transforms.ToTensor(),\n","    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n","                         std=[0.229, 0.224, 0.225])\n","])\n","## heatmap generation\n","def generate_gradcam(image_tensor, model):\n","    target_layer = model.features[-1]\n","    cam = GradCAM(model=model, target_layers=[target_layer])\n","    grayscale_cam = cam(input_tensor=image_tensor, targets=None)\n","    return grayscale_cam[0, :]\n","\n","\n","def apply_gradcam_to_image(original_image, gradcam):\n","    original_image = original_image.resize((224, 224))\n","    img_np = np.array(original_image) / 255.0\n","\n","    if gradcam.shape != (224, 224):\n","        gradcam = cv2.resize(gradcam, (224, 224))\n","\n","    visualization = show_cam_on_image(img_np, gradcam, use_rgb=True)\n","\n","    import matplotlib\n","    matplotlib.use('Agg')\n","    import matplotlib.pyplot as plt\n","\n","    fig = plt.figure(figsize=(6, 5))\n","    ax = fig.add_subplot(111)\n","    im = ax.imshow(visualization)\n","    ax.axis('off')\n","\n","    cbar = plt.colorbar(im, ax=ax, fraction=0.04, pad=0.04)\n","    cbar.set_label('Model Focus Intensity', rotation=270, labelpad=20)\n","\n","    return fig\n","\n","def predict_waste(img):\n","    if img is None:\n","        return \"<p style='color:red;'>âš ï¸ Please upload an image.</p>\", None, None\n","\n","    transform = transforms.Compose([\n","        transforms.ToPILImage(),\n","        transforms.Resize((224, 224)),\n","        transforms.ToTensor()\n","    ])\n","\n","    img_tensor = transform(img).unsqueeze(0).to(DEVICE)\n","\n","    display_img = cv2.resize(img, (224, 224))\n","    display_img = display_img.astype(np.float32) / 255.0\n","\n","    with torch.no_grad():\n","        outputs = net(img_tensor)\n","        probs = torch.nn.functional.softmax(outputs, dim=1)[0]\n","\n","    predicted_idx = torch.argmax(probs).item()\n","    predicted_label = CLASSES[predicted_idx]\n","    confidence = probs[predicted_idx].item() * 100\n","\n","    THRESHOLD = 40\n","\n","    if confidence < THRESHOLD:\n","        warning_html = f\"\"\"\n","        <div style=\"\n","            background: rgba(255, 87, 87, 0.12);\n","            border-left: 6px solid #ff3b3b;\n","            padding: 18px;\n","            border-radius: 10px;\n","            color: #ff4d4d;\n","            font-size: 1.2rem;\n","            line-height: 1.6;\n","            box-shadow: 0 2px 8px rgba(0,0,0,0.25);\n","        \">\n","            <strong style=\"font-size:1.35rem; color:#ff5c5c;\">\n","                âš ï¸ Low Confidence Prediction\n","            </strong>\n","\n","            <p style=\"margin-top:10px; color:#ff6d6d;\">\n","                The model is only <strong>{confidence:.2f}%</strong> confident about this image.\n","            </p>\n","\n","            <p style=\"color:#ff8080;\">\n","                This does <strong>not</strong> appear to be a waste item.<br>\n","                Please upload a clearer image or ensure the object belongs to one of the 12 waste categories.\n","            </p>\n","        </div>\n","        \"\"\"\n","        return warning_html, None, None\n","\n","\n","\n","    prob_list = probs.cpu().numpy().tolist()\n","\n","    recyclable = predicted_label in [\"Glass\", \"Metal\", \"Paper\", \"Plastic\"]\n","    biodegradable = predicted_label in [\"Biological\"]\n","\n","    suggestion_list = SUGGESTIONS.get(predicted_label, [\"No suggestions available.\"])\n","    suggestions_html = \"\".join([f\"<li>{s}</li>\" for s in suggestion_list])\n","\n","    result_html = f\"\"\"\n","    <div style=\"font-size:1.15rem; line-height:1.6;\">\n","        <p><strong>ğŸ¯ Predicted:</strong> {predicted_label}</p>\n","        <p><strong>ğŸ“Š Confidence:</strong> {confidence:.2f}%</p>\n","        <p><strong>â™»ï¸ Recyclable:</strong> {\"YES\" if recyclable else \"NO\"}</p>\n","        <p><strong>ğŸŒ± Biodegradable:</strong> {\"YES\" if biodegradable else \"NO\"}</p>\n","        <hr style=\"margin:15px 0; opacity:0.3;\">\n","  <h3 style=\"margin-bottom:8px;\">ğŸ’¡ Disposal Suggestions</h3>\n","  <ul style=\"margin-left:20px; font-size:1.1rem;\">\n","      {suggestions_html}\n","  </ul>\n","    </div>\n","    \"\"\"\n","\n","    def generate_gradcam(image_tensor, model):\n","        target_layer = model.features[-1]\n","        cam = GradCAM(model=model, target_layers=[target_layer])\n","        grayscale_cam = cam(input_tensor=image_tensor)\n","        return grayscale_cam[0]\n","\n","    gradcam_mask = generate_gradcam(img_tensor, net)\n","\n","    heatmap = cv2.applyColorMap((gradcam_mask * 255).astype(np.uint8),\n","                                cv2.COLORMAP_JET)\n","    heatmap = cv2.cvtColor(heatmap, cv2.COLOR_BGR2RGB)\n","    gradcam_img = (0.4 * heatmap + 0.6 * (display_img * 255)).astype(np.uint8)\n","\n","    fig_conf, ax = plt.subplots()\n","    ax.bar(CLASSES, prob_list)\n","    ax.set_ylabel(\"Probability\")\n","    ax.set_title(\"Model Confidence Distribution\")\n","    plt.xticks(rotation=45, ha='right')\n","    plt.tight_layout()\n","\n","    fig_cam, ax2 = plt.subplots()\n","\n","    im = ax2.imshow(gradcam_img)\n","    ax2.axis(\"off\")\n","    ax2.set_title(\"Grad-CAM Heatmap\")\n","\n","    cmap = mpl.cm.jet\n","    norm = mpl.colors.Normalize(vmin=0, vmax=1)\n","\n","    cbar = fig_cam.colorbar(\n","        mpl.cm.ScalarMappable(norm=norm, cmap=cmap),\n","        ax=ax2,\n","        fraction=0.046,\n","        pad=0.04\n","    )\n","    cbar.set_label(\"Attention Intensity (Blue â†’ Red)\", rotation=270, labelpad=15)\n","\n","    return result_html, fig_conf, fig_cam\n","\n","\n","\n","\n","with gr.Blocks(title=\"TrashScan: Smart Waste Classifier\", theme=gr.themes.Soft()) as demo:\n","\n","    gr.HTML(\"\"\"\n","    <style>\n","\n","    .main-container {\n","        max-width: 60%;\n","        margin: auto;\n","    }\n","\n","    #project_title {\n","        font-size: 3rem !important;\n","        font-weight: 800 !important;\n","        text-align: center;\n","        margin-top: 20px;\n","        margin-bottom: 5px;\n","        color: #00e676 !important;\n","    }\n","\n","    #project_subtitle {\n","        text-align: center;\n","        margin-bottom: 40px;\n","        font-size: 1.1rem;\n","        opacity: 0.9;\n","    }\n","\n","    .card {\n","        background: rgba(255,255,255,0.05);\n","        border-radius: 14px;\n","        padding: 20px;\n","        border: 1px solid rgba(255,255,255,0.1);\n","        box-shadow: 0 4px 12px rgba(0,0,0,0.2);\n","        margin-bottom: 25px;\n","    }\n","\n","    .result-card-content {\n","        font-size: 1.05rem;\n","        line-height: 1.55;\n","    }\n","\n","    </style>\n","    \"\"\")\n","\n","    gr.HTML(\"\"\"\n","    <h1 id='project_title'>â™»ï¸ TrashScan: Smart Waste Classifier</h1>\n","    <p id='project_subtitle'>Click. Scan. Dispose Right.</p>\n","    \"\"\")\n","\n","    with gr.Column(elem_classes=\"main-container\"):\n","\n","        with gr.Column(elem_classes=\"card\"):\n","            gr.Markdown(\"### ğŸ“¸ Upload\")\n","            image_input = gr.Image(type=\"numpy\", height=350)\n","            classify_btn = gr.Button(\"ğŸ” Classify\", variant=\"primary\")\n","\n","        with gr.Column(elem_classes=\"card\"):\n","            gr.Markdown(\"### ğŸ§¾ Results\")\n","            result_output = gr.HTML(elem_classes=\"result-card-content\")\n","\n","        with gr.Column(elem_classes=\"card\"):\n","            gr.Markdown(\"### ğŸ“ˆ Confidence\")\n","            chart_output = gr.Plot()\n","\n","        with gr.Column(elem_classes=\"card\"):\n","            gr.Markdown(\"### ğŸ”¥ Grad-CAM Visualization\")\n","            gradcam_output = gr.Plot()\n","\n","    classify_btn.click(\n","        fn=predict_waste,\n","        inputs=[image_input],\n","        outputs=[result_output, chart_output, gradcam_output]\n","    )\n","\n","    def clear_outputs(img):\n","        if img is None:\n","            return \"\", None, None\n","        return gr.update(), gr.update(), gr.update()\n","\n","    image_input.change(\n","        fn=clear_outputs,\n","        inputs=[image_input],\n","        outputs=[result_output, chart_output, gradcam_output]\n","    )\n","\n","\n","print(\"âœ“ Launching appâ€¦\")\n","demo.launch(share=True, show_error=True)"]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":677,"status":"ok","timestamp":1763787546834,"user":{"displayName":"ISHIKA KANYAL","userId":"01776562043666172481"},"user_tz":-330},"id":"f8NHB08tfB08","outputId":"56f45672-4ce9-4916-af78-8d0e4ed682f9"},"outputs":[{"output_type":"stream","name":"stdout","text":["Overwriting /content/gdrive/MyDrive/WasteClassification/requirements.txt\n"]}],"source":["%%writefile /content/gdrive/MyDrive/WasteClassification/requirements.txt\n","torch\n","torchvision\n","pillow\n","opencv-python\n","pytorch-grad-cam\n","gradio\n","numpy\n","matplotlib\n"]},{"cell_type":"code","execution_count":7,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"QrQmnxYuvj5F","outputId":"9df996a8-578a-4f4f-9941-cb59c0842b2e","executionInfo":{"status":"ok","timestamp":1763787624929,"user_tz":-330,"elapsed":57942,"user":{"displayName":"ISHIKA KANYAL","userId":"01776562043666172481"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Using device: cuda\n","âœ“ Model loaded successfully!\n","âœ“ Launching appâ€¦\n","* Running on local URL:  http://127.0.0.1:7860\n","* Running on public URL: https://d8cd445fe919f49bce.gradio.live\n","\n","This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n","Keyboard interruption in main thread... closing server.\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.12/dist-packages/gradio/blocks.py\", line 2958, in block_thread\n","    time.sleep(0.1)\n","KeyboardInterrupt\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/content/gdrive/MyDrive/WasteClassification/app.py\", line 304, in <module>\n","    demo.launch(share=True, show_error=True)\n","  File \"/usr/local/lib/python3.12/dist-packages/gradio/blocks.py\", line 2865, in launch\n","    self.block_thread()\n","  File \"/usr/local/lib/python3.12/dist-packages/gradio/blocks.py\", line 2962, in block_thread\n","    self.server.close()\n","  File \"/usr/local/lib/python3.12/dist-packages/gradio/http_server.py\", line 69, in close\n","    self.thread.join(timeout=5)\n","  File \"/usr/lib/python3.12/threading.py\", line 1153, in join\n","    self._wait_for_tstate_lock(timeout=max(timeout, 0))\n","  File \"/usr/lib/python3.12/threading.py\", line 1169, in _wait_for_tstate_lock\n","    if lock.acquire(block, timeout):\n","       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","KeyboardInterrupt\n","Killing tunnel 127.0.0.1:7860 <> https://d8cd445fe919f49bce.gradio.live\n"]}],"source":["!python /content/gdrive/MyDrive/WasteClassification/app.py\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zXxr91Scvmsq"},"outputs":[],"source":[]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[],"authorship_tag":"ABX9TyPClyKcB3ZyIiDN8lkyurXp"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}